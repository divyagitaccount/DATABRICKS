{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0108263e-bb49-4d48-8d1b-583144d68730",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#READ AND WRITE OPERATIONS IN PYSPARK\n",
    "\n",
    "DATAESET LINK:https://drive.google.com/drive/folders/1Tw7V9eBtUxy0xQMW38z3-bzWI_ewzLm6?usp=drive_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa2feb49-819c-4703-88cd-961b6fb8ecaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create catalog if not exists customer_catalog;\n",
    "create schema if not exists customer_catalog.customer_schema;\n",
    "create volume if not exists customer_catalog.customer_schema.customer_volume;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dba117ff-f2d2-4766-929c-3de71de8f10a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"/Volumes/customer_catalog/customer_schema/customer_volume/customer_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0168e3a-c62f-4327-bb2e-a0abaad41ed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "spark=SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b4a7682-ad04-4239-88c8-4111763978d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Header Concept\n",
    "df=spark.read.csv(\"/Volumes/customer_catalog/customer_schema/customer_volume/customer_data/custs\",header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0aca901-ec8f-43bd-a2cf-0d4f4fa59ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2. Printing Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "842625d9-d677-4561-a4f3-3ea56d0765aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#3. Inferring Schema\n",
    "df=spark.read.csv(\"/Volumes/customer_catalog/customer_schema/customer_volume/customer_data/custs\",inferSchema=\"true\").toDF(\"id\",\"fname\",\"lname\",\"age\",\"profession\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdb1b014-c5e9-4dec-96a3-0caa63222059",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#4. Using different options \n",
    "df=spark.read.options(header=\"true\",inferSchema=\"true\",sep=\",\").csv(\"/Volumes/customer_catalog/customer_schema/customer_volume/customer_data/custs_header\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84893bc4-18db-48e4-b91f-7bfefeec9458",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Generic way of read and load data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db183abd-ef02-4010-8564-9d2d8de431bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.format(\"csv\").options(header=\"true\",inferSchema=\"true\",sep=\",\").load(\"/Volumes/customer_catalog/customer_schema/customer_volume/customer_data/custs_header\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59743318-2f16-4052-896c-38a884395904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6589fde-2a1b-4c7b-bdae-611f4a00a7e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Reading data from multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "126d1e13-47b8-47df-99f0-5d96d0ccc675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"/Volumes/customer_catalog/customer_schema/customer_volume/customer_data/custs*\",header=\"true\",inferSchema=\"true\",sep=\",\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cac3600-1573-4bf0-9096-da6f55cf9d85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Provide schema with SQL String or programatically\n",
    "\n",
    "[PySpark SQL Datatypes](https://spark.apache.org/docs/latest/sql-ref-datatypes.html) <br>\n",
    "[Data Types](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/data_types.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23679d86-5792-4706-868d-aa59360467ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_sql = \"\"\"\n",
    "  cust_id INT,\n",
    "  custf_name STRING,\n",
    "  custl_name STRING,\n",
    "  age INT,\n",
    "  profession STRING\n",
    "\"\"\" # multi line string\n",
    "df = spark.read.option(\"header\", \"true\").schema(schema_sql).csv(\"/Volumes/customer_catalog/customer_schema/customer_volume/customer_data/custs*\")\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "#customising our schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f59d15b7-76dc-4b88-91d1-894108dcadb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fater than inferschema ,also avoid default string assumption\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"cust_id\", IntegerType(), True),\n",
    "    StructField(\"custf_name\", StringType(), True),\n",
    "    StructField(\"custl_name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"profession\", StringType(), True),\n",
    "]) # true denotes that the column allow null values\n",
    "df=spark.read.option(\"header\",\"true\").schema(schema).csv(\"/Volumes/customer_catalog/customer_schema/customer_volume/customer_data/custs*\")\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8215439597682517,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "READ AND WRITE OPERATIONS",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
